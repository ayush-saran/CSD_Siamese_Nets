{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "import argparse\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading face embeddings...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading face embeddings...\")\n",
    "data = pickle.loads(open('embeddings.pickle', \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Activation, Lambda, Permute, Reshape\n",
    "from keras import backend as K\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 1, 128)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 1, 128)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, 1, 32)        26848       input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1, 32)        0           sequential_5[1][0]               \n",
      "                                                                 sequential_5[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1, 1)         33          lambda_5[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 26,881\n",
      "Trainable params: 26,881\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Om\\Anaconda3\\envs\\opencv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "left_input=Input(shape=(1,128))\n",
    "right_input=Input(shape=(1,128))\n",
    "model=Sequential()\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "encoded_L=model(left_input)\n",
    "encoded_R=model(right_input)\n",
    "L1_layer=Lambda(lambda tensors:K.abs(tensors[0]-tensors[1]))\n",
    "L1_distance=L1_layer([encoded_L,encoded_R])\n",
    "prediction= Dense(1,activation='sigmoid')(L1_distance)\n",
    "siamese_net=Model(inputs=[left_input,right_input],output=prediction)\n",
    "siamese_net.compile(loss='binary_crossentropy',metrics=['acc'],optimizer='Adam')\n",
    "siamese_net.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from random import randint\n",
    "import numpy as np\n",
    "def random_pair(data):\n",
    "    y_train=np.zeros((1000,1))\n",
    "    left_input=[]\n",
    "    right_input=[]\n",
    "    for count in range(1000):\n",
    "        left=randint(0,49)\n",
    "        right=randint(0,49)\n",
    "        if(right!=left):\n",
    "            if(data['names'][left]==data['names'][right]):\n",
    "                y_train[count]=1\n",
    "            else:\n",
    "                y_train[count]=0\n",
    "            if count==0:\n",
    "                left_input=data['embeddings'][left]\n",
    "                right_input=data['embeddings'][right]\n",
    "            else:\n",
    "                left_input=np.vstack((left_input,data['embeddings'][left]))\n",
    "                right_input=np.vstack((right_input,data['embeddings'][right]))\n",
    "        else:\n",
    "            count=count-1\n",
    "            continue\n",
    "    return left_input,right_input,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pair(data):\n",
    "    y_train=np.zeros((2500,1))\n",
    "    left_input=[]\n",
    "    right_input=[]\n",
    "    count=0\n",
    "    for left in range(50):\n",
    "        for right in range(50):\n",
    "            if(data['names'][left]==data['names'][right]):\n",
    "                y_train[count]=1\n",
    "            else:\n",
    "                y_train[count]=0\n",
    "            if count==0:\n",
    "                left_input=data['embeddings'][left]\n",
    "                right_input=data['embeddings'][right]\n",
    "            else:\n",
    "                left_input=np.vstack((left_input,data['embeddings'][left]))\n",
    "                right_input=np.vstack((right_input,data['embeddings'][right]))\n",
    "            count=count+1\n",
    "    return left_input,right_input,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 128)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_input,right_input,y_train=random_pair(data)\n",
    "left_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_input_reshape=left_input.reshape(left_input.shape[0],1,128)\n",
    "right_input_reshape=right_input.reshape(right_input.shape[0],1,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cut=np.delete(y_train,np.s_[right_input_reshape.shape[0]:],0)\n",
    "y_train_reshape=y_train_cut.reshape(right_input_reshape.shape[0],1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/500\n",
      "2000/2000 [==============================] - 2s 958us/step - loss: 0.6647 - acc: 0.7750 - val_loss: 0.6435 - val_acc: 0.8000\n",
      "Epoch 2/500\n",
      "2000/2000 [==============================] - 0s 47us/step - loss: 0.5944 - acc: 0.8000 - val_loss: 0.5875 - val_acc: 0.8000\n",
      "Epoch 3/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.5115 - acc: 0.8000 - val_loss: 0.5285 - val_acc: 0.8000\n",
      "Epoch 4/500\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.4614 - acc: 0.785 - 0s 28us/step - loss: 0.4330 - acc: 0.8000 - val_loss: 0.4794 - val_acc: 0.8000\n",
      "Epoch 5/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.3756 - acc: 0.8000 - val_loss: 0.4422 - val_acc: 0.8000\n",
      "Epoch 6/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.3352 - acc: 0.8000 - val_loss: 0.4143 - val_acc: 0.8000\n",
      "Epoch 7/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.3063 - acc: 0.8000 - val_loss: 0.3943 - val_acc: 0.8000\n",
      "Epoch 8/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.2867 - acc: 0.8000 - val_loss: 0.3795 - val_acc: 0.8000\n",
      "Epoch 9/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.2723 - acc: 0.8000 - val_loss: 0.3688 - val_acc: 0.8000\n",
      "Epoch 10/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.2616 - acc: 0.8000 - val_loss: 0.3596 - val_acc: 0.8000\n",
      "Epoch 11/500\n",
      "2000/2000 [==============================] - 0s 26us/step - loss: 0.2529 - acc: 0.8000 - val_loss: 0.3570 - val_acc: 0.8000\n",
      "Epoch 12/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.2462 - acc: 0.8000 - val_loss: 0.3564 - val_acc: 0.8000\n",
      "Epoch 13/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.2401 - acc: 0.8000 - val_loss: 0.3570 - val_acc: 0.8000\n",
      "Epoch 14/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.2351 - acc: 0.8000 - val_loss: 0.3551 - val_acc: 0.8000\n",
      "Epoch 15/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.2301 - acc: 0.8000 - val_loss: 0.3643 - val_acc: 0.8000\n",
      "Epoch 16/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.2254 - acc: 0.8000 - val_loss: 0.3640 - val_acc: 0.8000\n",
      "Epoch 17/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.2211 - acc: 0.8055 - val_loss: 0.3682 - val_acc: 0.8000\n",
      "Epoch 18/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.2172 - acc: 0.8190 - val_loss: 0.3753 - val_acc: 0.8000\n",
      "Epoch 19/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.2133 - acc: 0.8395 - val_loss: 0.3687 - val_acc: 0.8000\n",
      "Epoch 20/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.2099 - acc: 0.8615 - val_loss: 0.3775 - val_acc: 0.8000\n",
      "Epoch 21/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.2054 - acc: 0.8850 - val_loss: 0.3670 - val_acc: 0.7980\n",
      "Epoch 22/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.2018 - acc: 0.9040 - val_loss: 0.3681 - val_acc: 0.7960\n",
      "Epoch 23/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.1987 - acc: 0.9205 - val_loss: 0.3597 - val_acc: 0.7940\n",
      "Epoch 24/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.1960 - acc: 0.9280 - val_loss: 0.3527 - val_acc: 0.7920\n",
      "Epoch 25/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.1925 - acc: 0.9405 - val_loss: 0.3449 - val_acc: 0.7880\n",
      "Epoch 26/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.1895 - acc: 0.9545 - val_loss: 0.3442 - val_acc: 0.8160\n",
      "Epoch 27/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.1862 - acc: 0.9725 - val_loss: 0.3292 - val_acc: 0.8100\n",
      "Epoch 28/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.1824 - acc: 0.9770 - val_loss: 0.3383 - val_acc: 0.8100\n",
      "Epoch 29/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.1791 - acc: 0.9845 - val_loss: 0.3263 - val_acc: 0.8140\n",
      "Epoch 30/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.1741 - acc: 0.9865 - val_loss: 0.3330 - val_acc: 0.8220\n",
      "Epoch 31/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.1708 - acc: 0.9905 - val_loss: 0.3252 - val_acc: 0.8120\n",
      "Epoch 32/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.1665 - acc: 0.9920 - val_loss: 0.3343 - val_acc: 0.8080\n",
      "Epoch 33/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.1626 - acc: 0.9920 - val_loss: 0.3416 - val_acc: 0.8060\n",
      "Epoch 34/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.1591 - acc: 0.9950 - val_loss: 0.3546 - val_acc: 0.8060\n",
      "Epoch 35/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.1558 - acc: 0.9950 - val_loss: 0.3558 - val_acc: 0.8060\n",
      "Epoch 36/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.1527 - acc: 0.9955 - val_loss: 0.3557 - val_acc: 0.8060\n",
      "Epoch 37/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.1499 - acc: 0.9955 - val_loss: 0.3671 - val_acc: 0.8140\n",
      "Epoch 38/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.1472 - acc: 0.9965 - val_loss: 0.3690 - val_acc: 0.8140\n",
      "Epoch 39/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.1449 - acc: 0.9965 - val_loss: 0.3608 - val_acc: 0.8140\n",
      "Epoch 40/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.1428 - acc: 0.9960 - val_loss: 0.3649 - val_acc: 0.8140\n",
      "Epoch 41/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.1405 - acc: 0.9965 - val_loss: 0.3715 - val_acc: 0.8140\n",
      "Epoch 42/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.1386 - acc: 0.9965 - val_loss: 0.3666 - val_acc: 0.8140\n",
      "Epoch 43/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.1366 - acc: 0.9965 - val_loss: 0.3607 - val_acc: 0.8140\n",
      "Epoch 44/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.1346 - acc: 0.9965 - val_loss: 0.3725 - val_acc: 0.8140\n",
      "Epoch 45/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.1331 - acc: 0.9970 - val_loss: 0.3624 - val_acc: 0.8180\n",
      "Epoch 46/500\n",
      "2000/2000 [==============================] - 0s 26us/step - loss: 0.1309 - acc: 0.9970 - val_loss: 0.3596 - val_acc: 0.8160\n",
      "Epoch 47/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.1292 - acc: 0.9970 - val_loss: 0.3646 - val_acc: 0.8180\n",
      "Epoch 48/500\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.1275 - acc: 0.9975 - val_loss: 0.3664 - val_acc: 0.8200\n",
      "Epoch 49/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.1258 - acc: 0.9980 - val_loss: 0.3668 - val_acc: 0.8220\n",
      "Epoch 50/500\n",
      "2000/2000 [==============================] - 0s 47us/step - loss: 0.1242 - acc: 0.9985 - val_loss: 0.3691 - val_acc: 0.8240\n",
      "Epoch 51/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.1228 - acc: 0.9985 - val_loss: 0.3623 - val_acc: 0.8240\n",
      "Epoch 52/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.1222 - acc: 0.9995 - val_loss: 0.3577 - val_acc: 0.8300\n",
      "Epoch 53/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.1206 - acc: 0.9995 - val_loss: 0.3489 - val_acc: 0.8300\n",
      "Epoch 54/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.1188 - acc: 0.9990 - val_loss: 0.3894 - val_acc: 0.8300\n",
      "Epoch 55/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.1183 - acc: 0.9990 - val_loss: 0.3467 - val_acc: 0.8300\n",
      "Epoch 56/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.1161 - acc: 0.9995 - val_loss: 0.3821 - val_acc: 0.8300\n",
      "Epoch 57/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.1140 - acc: 0.9995 - val_loss: 0.3488 - val_acc: 0.8280\n",
      "Epoch 58/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.1127 - acc: 0.9990 - val_loss: 0.3663 - val_acc: 0.8300\n",
      "Epoch 59/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.1113 - acc: 1.0000 - val_loss: 0.3724 - val_acc: 0.8320\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.1099 - acc: 1.0000 - val_loss: 0.3564 - val_acc: 0.8320\n",
      "Epoch 61/500\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.1084 - acc: 0.9995 - val_loss: 0.3454 - val_acc: 0.8320\n",
      "Epoch 62/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.1072 - acc: 0.9995 - val_loss: 0.3683 - val_acc: 0.8320\n",
      "Epoch 63/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.1058 - acc: 1.0000 - val_loss: 0.3463 - val_acc: 0.8400\n",
      "Epoch 64/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.1044 - acc: 1.0000 - val_loss: 0.3597 - val_acc: 0.8400\n",
      "Epoch 65/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.1030 - acc: 1.0000 - val_loss: 0.3541 - val_acc: 0.8440\n",
      "Epoch 66/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.1017 - acc: 0.9995 - val_loss: 0.3428 - val_acc: 0.8400\n",
      "Epoch 67/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.1004 - acc: 1.0000 - val_loss: 0.3578 - val_acc: 0.8440\n",
      "Epoch 68/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0990 - acc: 1.0000 - val_loss: 0.3465 - val_acc: 0.8440\n",
      "Epoch 69/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0979 - acc: 1.0000 - val_loss: 0.3419 - val_acc: 0.8440\n",
      "Epoch 70/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0968 - acc: 1.0000 - val_loss: 0.3449 - val_acc: 0.8440\n",
      "Epoch 71/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0959 - acc: 1.0000 - val_loss: 0.3604 - val_acc: 0.8520\n",
      "Epoch 72/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0945 - acc: 1.0000 - val_loss: 0.3303 - val_acc: 0.8520\n",
      "Epoch 73/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0928 - acc: 1.0000 - val_loss: 0.3462 - val_acc: 0.8520\n",
      "Epoch 74/500\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.0919 - acc: 1.0000 - val_loss: 0.3335 - val_acc: 0.8520\n",
      "Epoch 75/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0906 - acc: 1.0000 - val_loss: 0.3444 - val_acc: 0.8520\n",
      "Epoch 76/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0894 - acc: 1.0000 - val_loss: 0.3177 - val_acc: 0.8520\n",
      "Epoch 77/500\n",
      "2000/2000 [==============================] - 0s 49us/step - loss: 0.0884 - acc: 0.9995 - val_loss: 0.3302 - val_acc: 0.8520\n",
      "Epoch 78/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0871 - acc: 1.0000 - val_loss: 0.3327 - val_acc: 0.8600\n",
      "Epoch 79/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0859 - acc: 1.0000 - val_loss: 0.3231 - val_acc: 0.8600\n",
      "Epoch 80/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0849 - acc: 1.0000 - val_loss: 0.3382 - val_acc: 0.8600\n",
      "Epoch 81/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0838 - acc: 1.0000 - val_loss: 0.3185 - val_acc: 0.8600\n",
      "Epoch 82/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0829 - acc: 1.0000 - val_loss: 0.3405 - val_acc: 0.8600\n",
      "Epoch 83/500\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.0820 - acc: 1.0000 - val_loss: 0.3257 - val_acc: 0.8600\n",
      "Epoch 84/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0811 - acc: 1.0000 - val_loss: 0.3110 - val_acc: 0.8600\n",
      "Epoch 85/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0798 - acc: 1.0000 - val_loss: 0.3183 - val_acc: 0.8600\n",
      "Epoch 86/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0791 - acc: 0.9995 - val_loss: 0.3252 - val_acc: 0.8600\n",
      "Epoch 87/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0781 - acc: 1.0000 - val_loss: 0.3157 - val_acc: 0.8640\n",
      "Epoch 88/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0773 - acc: 1.0000 - val_loss: 0.3239 - val_acc: 0.8680\n",
      "Epoch 89/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0764 - acc: 0.9995 - val_loss: 0.3272 - val_acc: 0.8680\n",
      "Epoch 90/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0755 - acc: 1.0000 - val_loss: 0.3001 - val_acc: 0.8680\n",
      "Epoch 91/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0747 - acc: 1.0000 - val_loss: 0.3311 - val_acc: 0.8680\n",
      "Epoch 92/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0740 - acc: 1.0000 - val_loss: 0.3072 - val_acc: 0.8680\n",
      "Epoch 93/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0731 - acc: 1.0000 - val_loss: 0.2984 - val_acc: 0.8680\n",
      "Epoch 94/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0723 - acc: 1.0000 - val_loss: 0.3154 - val_acc: 0.8720\n",
      "Epoch 95/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0717 - acc: 0.9995 - val_loss: 0.3118 - val_acc: 0.8720\n",
      "Epoch 96/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0704 - acc: 1.0000 - val_loss: 0.2976 - val_acc: 0.8720\n",
      "Epoch 97/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0698 - acc: 1.0000 - val_loss: 0.3089 - val_acc: 0.8720\n",
      "Epoch 98/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0691 - acc: 1.0000 - val_loss: 0.3005 - val_acc: 0.8720\n",
      "Epoch 99/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0683 - acc: 1.0000 - val_loss: 0.2978 - val_acc: 0.8720\n",
      "Epoch 100/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0676 - acc: 1.0000 - val_loss: 0.3040 - val_acc: 0.8760\n",
      "Epoch 101/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0671 - acc: 1.0000 - val_loss: 0.2900 - val_acc: 0.8760\n",
      "Epoch 102/500\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.0661 - acc: 1.0000 - val_loss: 0.2962 - val_acc: 0.8760\n",
      "Epoch 103/500\n",
      "2000/2000 [==============================] - 0s 45us/step - loss: 0.0655 - acc: 1.0000 - val_loss: 0.2805 - val_acc: 0.8760\n",
      "Epoch 104/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0649 - acc: 1.0000 - val_loss: 0.2889 - val_acc: 0.8840\n",
      "Epoch 105/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0642 - acc: 1.0000 - val_loss: 0.2865 - val_acc: 0.8840\n",
      "Epoch 106/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0636 - acc: 1.0000 - val_loss: 0.2832 - val_acc: 0.8880\n",
      "Epoch 107/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0628 - acc: 1.0000 - val_loss: 0.2775 - val_acc: 0.8880\n",
      "Epoch 108/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0623 - acc: 1.0000 - val_loss: 0.2731 - val_acc: 0.8880\n",
      "Epoch 109/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0617 - acc: 1.0000 - val_loss: 0.2775 - val_acc: 0.8880\n",
      "Epoch 110/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0611 - acc: 1.0000 - val_loss: 0.2675 - val_acc: 0.8920\n",
      "Epoch 111/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0606 - acc: 1.0000 - val_loss: 0.2713 - val_acc: 0.8920\n",
      "Epoch 112/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0600 - acc: 1.0000 - val_loss: 0.2666 - val_acc: 0.8920\n",
      "Epoch 113/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0596 - acc: 1.0000 - val_loss: 0.2664 - val_acc: 0.8920\n",
      "Epoch 114/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0588 - acc: 1.0000 - val_loss: 0.2555 - val_acc: 0.8960\n",
      "Epoch 115/500\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.0584 - acc: 1.0000 - val_loss: 0.2581 - val_acc: 0.9000\n",
      "Epoch 116/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0580 - acc: 1.0000 - val_loss: 0.2604 - val_acc: 0.9000\n",
      "Epoch 117/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0573 - acc: 1.0000 - val_loss: 0.2502 - val_acc: 0.9120\n",
      "Epoch 118/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0569 - acc: 1.0000 - val_loss: 0.2525 - val_acc: 0.9000\n",
      "Epoch 119/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0563 - acc: 1.0000 - val_loss: 0.2581 - val_acc: 0.9080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0557 - acc: 1.0000 - val_loss: 0.2433 - val_acc: 0.9240\n",
      "Epoch 121/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0555 - acc: 1.0000 - val_loss: 0.2503 - val_acc: 0.9240\n",
      "Epoch 122/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0546 - acc: 1.0000 - val_loss: 0.2467 - val_acc: 0.9200\n",
      "Epoch 123/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0544 - acc: 1.0000 - val_loss: 0.2503 - val_acc: 0.9240\n",
      "Epoch 124/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0539 - acc: 1.0000 - val_loss: 0.2397 - val_acc: 0.9240\n",
      "Epoch 125/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0535 - acc: 1.0000 - val_loss: 0.2417 - val_acc: 0.9240\n",
      "Epoch 126/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0530 - acc: 1.0000 - val_loss: 0.2404 - val_acc: 0.9240\n",
      "Epoch 127/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0525 - acc: 1.0000 - val_loss: 0.2352 - val_acc: 0.9240\n",
      "Epoch 128/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0522 - acc: 1.0000 - val_loss: 0.2370 - val_acc: 0.9280\n",
      "Epoch 129/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0519 - acc: 1.0000 - val_loss: 0.2380 - val_acc: 0.9240\n",
      "Epoch 130/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0512 - acc: 1.0000 - val_loss: 0.2282 - val_acc: 0.9320\n",
      "Epoch 131/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0509 - acc: 1.0000 - val_loss: 0.2358 - val_acc: 0.9320\n",
      "Epoch 132/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0504 - acc: 1.0000 - val_loss: 0.2344 - val_acc: 0.9280\n",
      "Epoch 133/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0502 - acc: 1.0000 - val_loss: 0.2361 - val_acc: 0.9320\n",
      "Epoch 134/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0497 - acc: 1.0000 - val_loss: 0.2196 - val_acc: 0.9400\n",
      "Epoch 135/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0493 - acc: 1.0000 - val_loss: 0.2336 - val_acc: 0.9320\n",
      "Epoch 136/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0488 - acc: 1.0000 - val_loss: 0.2291 - val_acc: 0.9320\n",
      "Epoch 137/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0485 - acc: 1.0000 - val_loss: 0.2267 - val_acc: 0.9400\n",
      "Epoch 138/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0481 - acc: 1.0000 - val_loss: 0.2242 - val_acc: 0.9400\n",
      "Epoch 139/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0476 - acc: 1.0000 - val_loss: 0.2273 - val_acc: 0.9400\n",
      "Epoch 140/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0473 - acc: 1.0000 - val_loss: 0.2236 - val_acc: 0.9400\n",
      "Epoch 141/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0469 - acc: 1.0000 - val_loss: 0.2254 - val_acc: 0.9400\n",
      "Epoch 142/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0466 - acc: 1.0000 - val_loss: 0.2240 - val_acc: 0.9400\n",
      "Epoch 143/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0462 - acc: 1.0000 - val_loss: 0.2263 - val_acc: 0.9400\n",
      "Epoch 144/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0460 - acc: 1.0000 - val_loss: 0.2202 - val_acc: 0.9400\n",
      "Epoch 145/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0456 - acc: 1.0000 - val_loss: 0.2234 - val_acc: 0.9480\n",
      "Epoch 146/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0453 - acc: 1.0000 - val_loss: 0.2118 - val_acc: 0.9520\n",
      "Epoch 147/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0450 - acc: 1.0000 - val_loss: 0.2267 - val_acc: 0.9440\n",
      "Epoch 148/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0446 - acc: 1.0000 - val_loss: 0.2144 - val_acc: 0.9400\n",
      "Epoch 149/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0443 - acc: 1.0000 - val_loss: 0.2239 - val_acc: 0.9520\n",
      "Epoch 150/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0440 - acc: 1.0000 - val_loss: 0.2087 - val_acc: 0.9520\n",
      "Epoch 151/500\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.0438 - acc: 1.0000 - val_loss: 0.2177 - val_acc: 0.9520\n",
      "Epoch 152/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0434 - acc: 1.0000 - val_loss: 0.2201 - val_acc: 0.9440\n",
      "Epoch 153/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0431 - acc: 1.0000 - val_loss: 0.2161 - val_acc: 0.9520\n",
      "Epoch 154/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0429 - acc: 1.0000 - val_loss: 0.2215 - val_acc: 0.9440\n",
      "Epoch 155/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0425 - acc: 1.0000 - val_loss: 0.2165 - val_acc: 0.9520\n",
      "Epoch 156/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0422 - acc: 1.0000 - val_loss: 0.2126 - val_acc: 0.9520\n",
      "Epoch 157/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0419 - acc: 1.0000 - val_loss: 0.2102 - val_acc: 0.9520\n",
      "Epoch 158/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0417 - acc: 1.0000 - val_loss: 0.2125 - val_acc: 0.9520\n",
      "Epoch 159/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0413 - acc: 1.0000 - val_loss: 0.2226 - val_acc: 0.9520\n",
      "Epoch 160/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0410 - acc: 1.0000 - val_loss: 0.2081 - val_acc: 0.9520\n",
      "Epoch 161/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0408 - acc: 1.0000 - val_loss: 0.2146 - val_acc: 0.9520\n",
      "Epoch 162/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0405 - acc: 1.0000 - val_loss: 0.2044 - val_acc: 0.9520\n",
      "Epoch 163/500\n",
      "2000/2000 [==============================] - 0s 46us/step - loss: 0.0403 - acc: 1.0000 - val_loss: 0.2168 - val_acc: 0.9520\n",
      "Epoch 164/500\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.0401 - acc: 1.0000 - val_loss: 0.2143 - val_acc: 0.9520\n",
      "Epoch 165/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0397 - acc: 1.0000 - val_loss: 0.2061 - val_acc: 0.9560\n",
      "Epoch 166/500\n",
      "2000/2000 [==============================] - 0s 48us/step - loss: 0.0395 - acc: 1.0000 - val_loss: 0.2095 - val_acc: 0.9520\n",
      "Epoch 167/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0392 - acc: 1.0000 - val_loss: 0.2140 - val_acc: 0.9520\n",
      "Epoch 168/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0389 - acc: 1.0000 - val_loss: 0.2049 - val_acc: 0.9520\n",
      "Epoch 169/500\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.0387 - acc: 1.0000 - val_loss: 0.2099 - val_acc: 0.9560\n",
      "Epoch 170/500\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.0385 - acc: 1.0000 - val_loss: 0.2073 - val_acc: 0.9520\n",
      "Epoch 171/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0382 - acc: 1.0000 - val_loss: 0.2099 - val_acc: 0.9560\n",
      "Epoch 172/500\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.0379 - acc: 1.0000 - val_loss: 0.2060 - val_acc: 0.9520\n",
      "Epoch 173/500\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.0377 - acc: 1.0000 - val_loss: 0.2133 - val_acc: 0.9560\n",
      "Epoch 174/500\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0375 - acc: 1.0000 - val_loss: 0.2052 - val_acc: 0.9560\n",
      "Epoch 175/500\n",
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.0373 - acc: 1.0000 - val_loss: 0.2175 - val_acc: 0.9520\n",
      "Epoch 176/500\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.0370 - acc: 1.0000 - val_loss: 0.1982 - val_acc: 0.9560\n",
      "Epoch 177/500\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.0369 - acc: 1.0000 - val_loss: 0.2090 - val_acc: 0.9560\n",
      "Epoch 178/500\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0366 - acc: 1.0000 - val_loss: 0.2008 - val_acc: 0.9560\n",
      "Epoch 179/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 38us/step - loss: 0.0364 - acc: 1.0000 - val_loss: 0.2082 - val_acc: 0.9560\n",
      "Epoch 180/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0361 - acc: 1.0000 - val_loss: 0.2070 - val_acc: 0.9560\n",
      "Epoch 181/500\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0360 - acc: 1.0000 - val_loss: 0.2102 - val_acc: 0.9520\n",
      "Epoch 182/500\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.0358 - acc: 1.0000 - val_loss: 0.1969 - val_acc: 0.9640\n",
      "Epoch 183/500\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0355 - acc: 1.0000 - val_loss: 0.2021 - val_acc: 0.9640\n",
      "Epoch 184/500\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.0352 - acc: 1.0000 - val_loss: 0.2102 - val_acc: 0.9520\n",
      "Epoch 185/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0351 - acc: 1.0000 - val_loss: 0.2074 - val_acc: 0.9560\n",
      "Epoch 186/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0349 - acc: 1.0000 - val_loss: 0.2065 - val_acc: 0.9560\n",
      "Epoch 187/500\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.0346 - acc: 1.0000 - val_loss: 0.2006 - val_acc: 0.9640\n",
      "Epoch 188/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0346 - acc: 1.0000 - val_loss: 0.2101 - val_acc: 0.9560\n",
      "Epoch 189/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0343 - acc: 1.0000 - val_loss: 0.1933 - val_acc: 0.9640\n",
      "Epoch 190/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0340 - acc: 1.0000 - val_loss: 0.2077 - val_acc: 0.9560\n",
      "Epoch 191/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0339 - acc: 1.0000 - val_loss: 0.2074 - val_acc: 0.9520\n",
      "Epoch 192/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0337 - acc: 1.0000 - val_loss: 0.2049 - val_acc: 0.9640\n",
      "Epoch 193/500\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.0335 - acc: 1.0000 - val_loss: 0.1991 - val_acc: 0.9560\n",
      "Epoch 194/500\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.0332 - acc: 1.0000 - val_loss: 0.2059 - val_acc: 0.9560\n",
      "Epoch 195/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0331 - acc: 1.0000 - val_loss: 0.2045 - val_acc: 0.9560\n",
      "Epoch 196/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.9640\n",
      "Epoch 197/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.1960 - val_acc: 0.9640\n",
      "Epoch 198/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0325 - acc: 1.0000 - val_loss: 0.2012 - val_acc: 0.9560\n",
      "Epoch 199/500\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0323 - acc: 1.0000 - val_loss: 0.2033 - val_acc: 0.9560\n",
      "Epoch 200/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0321 - acc: 1.0000 - val_loss: 0.2079 - val_acc: 0.9560\n",
      "Epoch 201/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0321 - acc: 1.0000 - val_loss: 0.2051 - val_acc: 0.9560\n",
      "Epoch 202/500\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.0317 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9640\n",
      "Epoch 203/500\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.1995 - val_acc: 0.9640\n",
      "Epoch 204/500\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.0315 - acc: 1.0000 - val_loss: 0.2082 - val_acc: 0.9560\n",
      "Epoch 205/500\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.1960 - val_acc: 0.9640\n",
      "Epoch 206/500\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0311 - acc: 1.0000 - val_loss: 0.2013 - val_acc: 0.9560\n",
      "Epoch 207/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0309 - acc: 1.0000 - val_loss: 0.1999 - val_acc: 0.9560\n",
      "Epoch 208/500\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.0308 - acc: 1.0000 - val_loss: 0.2070 - val_acc: 0.9560\n",
      "Epoch 209/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0306 - acc: 1.0000 - val_loss: 0.1977 - val_acc: 0.9640\n",
      "Epoch 210/500\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.1956 - val_acc: 0.9640\n",
      "Epoch 211/500\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.0302 - acc: 1.0000 - val_loss: 0.2032 - val_acc: 0.9560\n",
      "Epoch 212/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0301 - acc: 1.0000 - val_loss: 0.2015 - val_acc: 0.9560\n",
      "Epoch 213/500\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.2022 - val_acc: 0.9560\n",
      "Epoch 214/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0298 - acc: 1.0000 - val_loss: 0.1999 - val_acc: 0.9560\n",
      "Epoch 215/500\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.0296 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9640\n",
      "Epoch 216/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0294 - acc: 1.0000 - val_loss: 0.2024 - val_acc: 0.9560\n",
      "Epoch 217/500\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.0293 - acc: 1.0000 - val_loss: 0.1974 - val_acc: 0.9560\n",
      "Epoch 218/500\n",
      "2000/2000 [==============================] - 0s 45us/step - loss: 0.0292 - acc: 1.0000 - val_loss: 0.1953 - val_acc: 0.9640\n",
      "Epoch 219/500\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.0290 - acc: 1.0000 - val_loss: 0.2067 - val_acc: 0.9560\n",
      "Epoch 220/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.2028 - val_acc: 0.9560\n",
      "Epoch 221/500\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.1864 - val_acc: 0.9640\n",
      "Epoch 222/500\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.0286 - acc: 1.0000 - val_loss: 0.1933 - val_acc: 0.9640\n",
      "Epoch 223/500\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.1993 - val_acc: 0.9560\n",
      "Epoch 224/500\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.2052 - val_acc: 0.9560\n",
      "Epoch 225/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0281 - acc: 1.0000 - val_loss: 0.1938 - val_acc: 0.9640\n",
      "Epoch 226/500\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.0280 - acc: 1.0000 - val_loss: 0.1978 - val_acc: 0.9640\n",
      "Epoch 227/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.1938 - val_acc: 0.9640\n",
      "Epoch 228/500\n",
      "2000/2000 [==============================] - 0s 45us/step - loss: 0.0277 - acc: 1.0000 - val_loss: 0.1957 - val_acc: 0.9640\n",
      "Epoch 229/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0276 - acc: 1.0000 - val_loss: 0.2102 - val_acc: 0.9560\n",
      "Epoch 230/500\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.0275 - acc: 1.0000 - val_loss: 0.1882 - val_acc: 0.9640\n",
      "Epoch 231/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0272 - acc: 1.0000 - val_loss: 0.1975 - val_acc: 0.9640\n",
      "Epoch 232/500\n",
      "2000/2000 [==============================] - 0s 45us/step - loss: 0.0271 - acc: 1.0000 - val_loss: 0.2020 - val_acc: 0.9560\n",
      "Epoch 233/500\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.1969 - val_acc: 0.9640\n",
      "Epoch 234/500\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0268 - acc: 1.0000 - val_loss: 0.1961 - val_acc: 0.9560\n",
      "Epoch 235/500\n",
      "2000/2000 [==============================] - 0s 46us/step - loss: 0.0268 - acc: 1.0000 - val_loss: 0.1925 - val_acc: 0.9640\n",
      "Epoch 236/500\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.0266 - acc: 1.0000 - val_loss: 0.2010 - val_acc: 0.9560\n",
      "Epoch 237/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.1938 - val_acc: 0.9640\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.1923 - val_acc: 0.9640\n",
      "Epoch 239/500\n",
      "2000/2000 [==============================] - 0s 45us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.2034 - val_acc: 0.9560\n",
      "Epoch 240/500\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.1906 - val_acc: 0.9640\n",
      "Epoch 241/500\n",
      "2000/2000 [==============================] - 0s 44us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.1959 - val_acc: 0.9640\n",
      "Epoch 242/500\n",
      "2000/2000 [==============================] - 0s 45us/step - loss: 0.0258 - acc: 1.0000 - val_loss: 0.1953 - val_acc: 0.9560\n",
      "Epoch 243/500\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.1982 - val_acc: 0.9640\n",
      "Epoch 244/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0256 - acc: 1.0000 - val_loss: 0.1914 - val_acc: 0.9640\n",
      "Epoch 245/500\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.1991 - val_acc: 0.9560\n",
      "Epoch 246/500\n",
      "2000/2000 [==============================] - 0s 46us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.1932 - val_acc: 0.9640\n",
      "Epoch 247/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.1943 - val_acc: 0.9640\n",
      "Epoch 248/500\n",
      "2000/2000 [==============================] - 0s 43us/step - loss: 0.0251 - acc: 1.0000 - val_loss: 0.1867 - val_acc: 0.9640\n",
      "Epoch 249/500\n",
      "2000/2000 [==============================] - 0s 42us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.1981 - val_acc: 0.9640\n",
      "Epoch 250/500\n",
      "2000/2000 [==============================] - 0s 40us/step - loss: 0.0248 - acc: 1.0000 - val_loss: 0.1947 - val_acc: 0.9560\n",
      "Epoch 251/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.1972 - val_acc: 0.9640\n",
      "Epoch 252/500\n",
      "2000/2000 [==============================] - 0s 27us/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.1963 - val_acc: 0.9560\n",
      "Epoch 253/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0244 - acc: 1.0000 - val_loss: 0.1937 - val_acc: 0.9640\n",
      "Epoch 254/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0244 - acc: 1.0000 - val_loss: 0.1877 - val_acc: 0.9640\n",
      "Epoch 255/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.1923 - val_acc: 0.9640\n",
      "Epoch 256/500\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.2002 - val_acc: 0.9560\n",
      "Epoch 257/500\n",
      "2000/2000 [==============================] - 0s 48us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 0.9640\n",
      "Epoch 258/500\n",
      "2000/2000 [==============================] - 0s 39us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 0.9640\n",
      "Epoch 259/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9640\n",
      "Epoch 260/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0237 - acc: 1.0000 - val_loss: 0.2010 - val_acc: 0.9640\n",
      "Epoch 261/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.1903 - val_acc: 0.9640\n",
      "Epoch 262/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.1962 - val_acc: 0.9640\n",
      "Epoch 263/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.1868 - val_acc: 0.9640\n",
      "Epoch 264/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.1913 - val_acc: 0.9640\n",
      "Epoch 265/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.1919 - val_acc: 0.9640\n",
      "Epoch 266/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 0.9640\n",
      "Epoch 267/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.1908 - val_acc: 0.9640\n",
      "Epoch 268/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.1924 - val_acc: 0.9560\n",
      "Epoch 269/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 0.1921 - val_acc: 0.9640\n",
      "Epoch 270/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 0.1935 - val_acc: 0.9640\n",
      "Epoch 271/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.1903 - val_acc: 0.9640\n",
      "Epoch 272/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.1969 - val_acc: 0.9640\n",
      "Epoch 273/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.1871 - val_acc: 0.9640\n",
      "Epoch 274/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.1920 - val_acc: 0.9640\n",
      "Epoch 275/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.1941 - val_acc: 0.9560\n",
      "Epoch 276/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.1833 - val_acc: 0.9640\n",
      "Epoch 277/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.1800 - val_acc: 0.9640\n",
      "Epoch 278/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.1962 - val_acc: 0.9640\n",
      "Epoch 279/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.1896 - val_acc: 0.9640\n",
      "Epoch 280/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.1843 - val_acc: 0.9640\n",
      "Epoch 281/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.1974 - val_acc: 0.9560\n",
      "Epoch 282/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.1842 - val_acc: 0.9640\n",
      "Epoch 283/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.1897 - val_acc: 0.9640\n",
      "Epoch 284/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.1869 - val_acc: 0.9640\n",
      "Epoch 285/500\n",
      "2000/2000 [==============================] - 0s 27us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.1965 - val_acc: 0.9560\n",
      "Epoch 286/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.1861 - val_acc: 0.9640\n",
      "Epoch 287/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.1909 - val_acc: 0.9640\n",
      "Epoch 288/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.9560\n",
      "Epoch 289/500\n",
      "2000/2000 [==============================] - 0s 27us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.1861 - val_acc: 0.9640\n",
      "Epoch 290/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.1876 - val_acc: 0.9640\n",
      "Epoch 291/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.1853 - val_acc: 0.9640\n",
      "Epoch 292/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.1943 - val_acc: 0.9640\n",
      "Epoch 293/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.1933 - val_acc: 0.9640\n",
      "Epoch 294/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.1865 - val_acc: 0.9640\n",
      "Epoch 295/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.1962 - val_acc: 0.9640\n",
      "Epoch 296/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 0.1847 - val_acc: 0.9640\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.1875 - val_acc: 0.9640\n",
      "Epoch 298/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 0.9640\n",
      "Epoch 299/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.1918 - val_acc: 0.9640\n",
      "Epoch 300/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.1871 - val_acc: 0.9640\n",
      "Epoch 301/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.1850 - val_acc: 0.9640\n",
      "Epoch 302/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.1862 - val_acc: 0.9640\n",
      "Epoch 303/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.1872 - val_acc: 0.9640\n",
      "Epoch 304/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.1891 - val_acc: 0.9640\n",
      "Epoch 305/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.1886 - val_acc: 0.9640\n",
      "Epoch 306/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.1872 - val_acc: 0.9640\n",
      "Epoch 307/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.1935 - val_acc: 0.9640\n",
      "Epoch 308/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.1800 - val_acc: 0.9640\n",
      "Epoch 309/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.1929 - val_acc: 0.9640\n",
      "Epoch 310/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.1830 - val_acc: 0.9640\n",
      "Epoch 311/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.1886 - val_acc: 0.9640\n",
      "Epoch 312/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.1898 - val_acc: 0.9640\n",
      "Epoch 313/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.1890 - val_acc: 0.9640\n",
      "Epoch 314/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 0.9640\n",
      "Epoch 315/500\n",
      "2000/2000 [==============================] - 0s 27us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.1907 - val_acc: 0.9640\n",
      "Epoch 316/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.1873 - val_acc: 0.9640\n",
      "Epoch 317/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.1837 - val_acc: 0.9640\n",
      "Epoch 318/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.1930 - val_acc: 0.9640\n",
      "Epoch 319/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.1885 - val_acc: 0.9640\n",
      "Epoch 320/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.1899 - val_acc: 0.9640\n",
      "Epoch 321/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.1841 - val_acc: 0.9640\n",
      "Epoch 322/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.1882 - val_acc: 0.9640\n",
      "Epoch 323/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.1858 - val_acc: 0.9640\n",
      "Epoch 324/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.1908 - val_acc: 0.9640\n",
      "Epoch 325/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.1790 - val_acc: 0.9640\n",
      "Epoch 326/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.1870 - val_acc: 0.9640\n",
      "Epoch 327/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.1879 - val_acc: 0.9640\n",
      "Epoch 328/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.1800 - val_acc: 0.9640\n",
      "Epoch 329/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.1881 - val_acc: 0.9640\n",
      "Epoch 330/500\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.1891 - val_acc: 0.9640\n",
      "Epoch 331/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.1811 - val_acc: 0.9640\n",
      "Epoch 332/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.1873 - val_acc: 0.9640\n",
      "Epoch 333/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.1846 - val_acc: 0.9640\n",
      "Epoch 334/500\n",
      "2000/2000 [==============================] - 0s 27us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.1859 - val_acc: 0.9640\n",
      "Epoch 335/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.1935 - val_acc: 0.9640\n",
      "Epoch 336/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.1803 - val_acc: 0.9640\n",
      "Epoch 337/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.1815 - val_acc: 0.9640\n",
      "Epoch 338/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.1881 - val_acc: 0.9640\n",
      "Epoch 339/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.1860 - val_acc: 0.9640\n",
      "Epoch 340/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.1889 - val_acc: 0.9640\n",
      "Epoch 341/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.1829 - val_acc: 0.9640\n",
      "Epoch 342/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.1787 - val_acc: 0.9640\n",
      "Epoch 343/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.1904 - val_acc: 0.9640\n",
      "Epoch 344/500\n",
      "2000/2000 [==============================] - 0s 27us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.1866 - val_acc: 0.9640\n",
      "Epoch 345/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.1840 - val_acc: 0.9640\n",
      "Epoch 346/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.1829 - val_acc: 0.9640\n",
      "Epoch 347/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.1819 - val_acc: 0.9640\n",
      "Epoch 348/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.1868 - val_acc: 0.9640\n",
      "Epoch 349/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 0.9640\n",
      "Epoch 350/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.1786 - val_acc: 0.9640\n",
      "Epoch 351/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.1852 - val_acc: 0.9640\n",
      "Epoch 352/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.1877 - val_acc: 0.9640\n",
      "Epoch 353/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.1825 - val_acc: 0.9640\n",
      "Epoch 354/500\n",
      "2000/2000 [==============================] - 0s 27us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.1818 - val_acc: 0.9640\n",
      "Epoch 355/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.1849 - val_acc: 0.9640\n",
      "Epoch 356/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.1806 - val_acc: 0.9640\n",
      "Epoch 357/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.1841 - val_acc: 0.9640\n",
      "Epoch 358/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.1863 - val_acc: 0.9640\n",
      "Epoch 359/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.1818 - val_acc: 0.9640\n",
      "Epoch 360/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.1807 - val_acc: 0.9640\n",
      "Epoch 361/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.1864 - val_acc: 0.9640\n",
      "Epoch 362/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.1870 - val_acc: 0.9640\n",
      "Epoch 363/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.1787 - val_acc: 0.9640\n",
      "Epoch 364/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.1797 - val_acc: 0.9640\n",
      "Epoch 365/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.1866 - val_acc: 0.9640\n",
      "Epoch 366/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.1798 - val_acc: 0.9640\n",
      "Epoch 367/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.1814 - val_acc: 0.9640\n",
      "Epoch 368/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.1811 - val_acc: 0.9640\n",
      "Epoch 369/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.1824 - val_acc: 0.9640\n",
      "Epoch 370/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 0.9640\n",
      "Epoch 371/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 0.9640\n",
      "Epoch 372/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.1865 - val_acc: 0.9640\n",
      "Epoch 373/500\n",
      "2000/2000 [==============================] - 0s 41us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.1808 - val_acc: 0.9640\n",
      "Epoch 374/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.1793 - val_acc: 0.9640\n",
      "Epoch 375/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.1825 - val_acc: 0.9640\n",
      "Epoch 376/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.1825 - val_acc: 0.9640\n",
      "Epoch 377/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.1744 - val_acc: 0.9640\n",
      "Epoch 378/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.1777 - val_acc: 0.9640\n",
      "Epoch 379/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.1863 - val_acc: 0.9640\n",
      "Epoch 380/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.1793 - val_acc: 0.9640\n",
      "Epoch 381/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.1718 - val_acc: 0.9640\n",
      "Epoch 382/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.1827 - val_acc: 0.9640\n",
      "Epoch 383/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.1775 - val_acc: 0.9640\n",
      "Epoch 384/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.1830 - val_acc: 0.9640\n",
      "Epoch 385/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.1799 - val_acc: 0.9640\n",
      "Epoch 386/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.1742 - val_acc: 0.9640\n",
      "Epoch 387/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.1836 - val_acc: 0.9640\n",
      "Epoch 388/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.1798 - val_acc: 0.9640\n",
      "Epoch 389/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.1793 - val_acc: 0.9640\n",
      "Epoch 390/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.1794 - val_acc: 0.9640\n",
      "Epoch 391/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.1794 - val_acc: 0.9640\n",
      "Epoch 392/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.1766 - val_acc: 0.9640\n",
      "Epoch 393/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.1774 - val_acc: 0.9640\n",
      "Epoch 394/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.1802 - val_acc: 0.9640\n",
      "Epoch 395/500\n",
      "2000/2000 [==============================] - 0s 27us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.1780 - val_acc: 0.9640\n",
      "Epoch 396/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.1794 - val_acc: 0.9640\n",
      "Epoch 397/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.1712 - val_acc: 0.9640\n",
      "Epoch 398/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.1838 - val_acc: 0.9640\n",
      "Epoch 399/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.1773 - val_acc: 0.9640\n",
      "Epoch 400/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.1700 - val_acc: 0.9640\n",
      "Epoch 401/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.1813 - val_acc: 0.9640\n",
      "Epoch 402/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.1764 - val_acc: 0.9640\n",
      "Epoch 403/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.1819 - val_acc: 0.9640\n",
      "Epoch 404/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.1706 - val_acc: 0.9640\n",
      "Epoch 405/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.1815 - val_acc: 0.9640\n",
      "Epoch 406/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.1800 - val_acc: 0.9640\n",
      "Epoch 407/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.1740 - val_acc: 0.9640\n",
      "Epoch 408/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.1744 - val_acc: 0.9640\n",
      "Epoch 409/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.1782 - val_acc: 0.9640\n",
      "Epoch 410/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.1777 - val_acc: 0.9640\n",
      "Epoch 411/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.1744 - val_acc: 0.9640\n",
      "Epoch 412/500\n",
      "2000/2000 [==============================] - 0s 26us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.1668 - val_acc: 0.9640\n",
      "Epoch 413/500\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0177 - acc: 1.000 - 0s 28us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.1863 - val_acc: 0.9640\n",
      "Epoch 414/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.1711 - val_acc: 0.9640\n",
      "Epoch 415/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.1709 - val_acc: 0.9640\n",
      "Epoch 416/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.1799 - val_acc: 0.9640\n",
      "Epoch 417/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.1741 - val_acc: 0.9640\n",
      "Epoch 418/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.1811 - val_acc: 0.9640\n",
      "Epoch 419/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.1708 - val_acc: 0.9640\n",
      "Epoch 420/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.1652 - val_acc: 0.9640\n",
      "Epoch 421/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.1761 - val_acc: 0.9640\n",
      "Epoch 422/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.1736 - val_acc: 0.9640\n",
      "Epoch 423/500\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.1734 - val_acc: 0.9640\n",
      "Epoch 424/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.1810 - val_acc: 0.9640\n",
      "Epoch 425/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.1730 - val_acc: 0.9640\n",
      "Epoch 426/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.1675 - val_acc: 0.9640\n",
      "Epoch 427/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.1718 - val_acc: 0.9640\n",
      "Epoch 428/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.1753 - val_acc: 0.9640\n",
      "Epoch 429/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.1710 - val_acc: 0.9640\n",
      "Epoch 430/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.1716 - val_acc: 0.9640\n",
      "Epoch 431/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.1722 - val_acc: 0.9640\n",
      "Epoch 432/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.1744 - val_acc: 0.9640\n",
      "Epoch 433/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.1723 - val_acc: 0.9640\n",
      "Epoch 434/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.1704 - val_acc: 0.9640\n",
      "Epoch 435/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.1753 - val_acc: 0.9640\n",
      "Epoch 436/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.1684 - val_acc: 0.9640\n",
      "Epoch 437/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.1725 - val_acc: 0.9640\n",
      "Epoch 438/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.1712 - val_acc: 0.9640\n",
      "Epoch 439/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.1705 - val_acc: 0.9640\n",
      "Epoch 440/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.1713 - val_acc: 0.9640\n",
      "Epoch 441/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.1706 - val_acc: 0.9640\n",
      "Epoch 442/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.1714 - val_acc: 0.9640\n",
      "Epoch 443/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.1705 - val_acc: 0.9640\n",
      "Epoch 444/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.1697 - val_acc: 0.9640\n",
      "Epoch 445/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.1712 - val_acc: 0.9640\n",
      "Epoch 446/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.1708 - val_acc: 0.9640\n",
      "Epoch 447/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.1694 - val_acc: 0.9640\n",
      "Epoch 448/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.1701 - val_acc: 0.9640\n",
      "Epoch 449/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.1669 - val_acc: 0.9640\n",
      "Epoch 450/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.1706 - val_acc: 0.9640\n",
      "Epoch 451/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.1699 - val_acc: 0.9640\n",
      "Epoch 452/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.1697 - val_acc: 0.9640\n",
      "Epoch 453/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.1736 - val_acc: 0.9640\n",
      "Epoch 454/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.1628 - val_acc: 0.9640\n",
      "Epoch 455/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.1679 - val_acc: 0.9640\n",
      "Epoch 456/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.1721 - val_acc: 0.9640\n",
      "Epoch 457/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.1668 - val_acc: 0.9640\n",
      "Epoch 458/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.1653 - val_acc: 0.9640\n",
      "Epoch 459/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.1770 - val_acc: 0.9640\n",
      "Epoch 460/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.1634 - val_acc: 0.9640\n",
      "Epoch 461/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.1671 - val_acc: 0.9640\n",
      "Epoch 462/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.1666 - val_acc: 0.9640\n",
      "Epoch 463/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.1663 - val_acc: 0.9640\n",
      "Epoch 464/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.1731 - val_acc: 0.9640\n",
      "Epoch 465/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.1694 - val_acc: 0.9640\n",
      "Epoch 466/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.1663 - val_acc: 0.9640\n",
      "Epoch 467/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.1675 - val_acc: 0.9640\n",
      "Epoch 468/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.1695 - val_acc: 0.9640\n",
      "Epoch 469/500\n",
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.1645 - val_acc: 0.9640\n",
      "Epoch 470/500\n",
      "2000/2000 [==============================] - 0s 27us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.1686 - val_acc: 0.9640\n",
      "Epoch 471/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.1681 - val_acc: 0.9640\n",
      "Epoch 472/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.1661 - val_acc: 0.9640\n",
      "Epoch 473/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.1597 - val_acc: 0.9640\n",
      "Epoch 474/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 28us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.1618 - val_acc: 0.9640\n",
      "Epoch 475/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.1420 - val_acc: 0.9640\n",
      "Epoch 476/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.1437 - val_acc: 0.9640\n",
      "Epoch 477/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.1481 - val_acc: 0.9640\n",
      "Epoch 478/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.1453 - val_acc: 0.9640\n",
      "Epoch 479/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.1414 - val_acc: 0.9640\n",
      "Epoch 480/500\n",
      "2000/2000 [==============================] - 0s 36us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.1406 - val_acc: 0.9640\n",
      "Epoch 481/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 0.9640\n",
      "Epoch 482/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.1304 - val_acc: 0.9640\n",
      "Epoch 483/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.1442 - val_acc: 0.9640\n",
      "Epoch 484/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.1387 - val_acc: 0.9640\n",
      "Epoch 485/500\n",
      "2000/2000 [==============================] - 0s 34us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.1308 - val_acc: 0.9640\n",
      "Epoch 486/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.1319 - val_acc: 0.9640\n",
      "Epoch 487/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9640\n",
      "Epoch 488/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.1253 - val_acc: 0.9640\n",
      "Epoch 489/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.1054 - val_acc: 0.9640\n",
      "Epoch 490/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.1010 - val_acc: 0.9640\n",
      "Epoch 491/500\n",
      "2000/2000 [==============================] - 0s 35us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.1023 - val_acc: 0.9640\n",
      "Epoch 492/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.1061 - val_acc: 0.9640\n",
      "Epoch 493/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.1069 - val_acc: 0.9640\n",
      "Epoch 494/500\n",
      "2000/2000 [==============================] - 0s 31us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.1002 - val_acc: 0.9640\n",
      "Epoch 495/500\n",
      "2000/2000 [==============================] - 0s 30us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 0.9640\n",
      "Epoch 496/500\n",
      "2000/2000 [==============================] - 0s 37us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0875 - val_acc: 0.9640\n",
      "Epoch 497/500\n",
      "2000/2000 [==============================] - 0s 32us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0773 - val_acc: 0.9640\n",
      "Epoch 498/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0744 - val_acc: 0.9640\n",
      "Epoch 499/500\n",
      "2000/2000 [==============================] - 0s 29us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0708 - val_acc: 0.9760\n",
      "Epoch 500/500\n",
      "2000/2000 [==============================] - 0s 33us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0696 - val_acc: 0.9760\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPOCH=500\n",
    "BATCH=256\n",
    "\n",
    "history=siamese_net.fit([left_input_reshape,right_input_reshape],y_train_reshape,epochs=EPOCH,batch_size=BATCH,validation_split=0.2)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the actual face recognition model to disk\n",
    "f = open(\"recognizer_siamese.pickle\", \"wb\")\n",
    "f.write(pickle.dumps(siamese_net))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
