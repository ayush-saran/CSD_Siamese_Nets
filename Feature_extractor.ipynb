{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Om\\Anaconda3\\envs\\opencv\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "trial_model=load_model(\"C:\\\\Users\\\\Om\\\\Desktop\\\\Cerberus\\\\Utilities\\\\VGGFace.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(featmodel, crpimg, transform=False): #extract face feature vector\n",
    "    \n",
    "    # transform=True seems more robust but I think the RGB channels are not in right order\n",
    "    \n",
    "    imarr = np.array(crpimg).astype(np.float32)\n",
    "\n",
    "    if transform:\n",
    "        imarr[:,:,0] -= 129.1863\n",
    "        imarr[:,:,1] -= 104.7624\n",
    "        imarr[:,:,2] -= 93.5940        \n",
    "        aux = copy.copy(imarr)\n",
    "    imarr = np.expand_dims(imarr, axis=0)\n",
    "    output= featmodel.predict(imarr)[0,:]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(inpDir,personID,wordID,timestep): #access directory and extract face vector     \n",
    "        \n",
    "    sample_space=[] #for appending different utterances\n",
    "    feature_sequence = [] # for appending different timesteps\n",
    "    inpDir=inpDir #input dataset\n",
    "    linpDir = os.listdir(inpDir) #list all directories in dataset\n",
    "    #print(linpDir)\n",
    "    personStr= linpDir[personID]\n",
    "    personFolder = '%s\\\\%s\\\\words' % (inpDir,personStr) #opening words folder\n",
    "    lpersonFolder = os.listdir(personFolder)\n",
    "    wordID= lpersonFolder[wordID]\n",
    "    wordFolder = '%s\\\\%s' % (personFolder,wordID)\n",
    "    lwordFolder = os.listdir(wordFolder)\n",
    "    i=0\n",
    "    for utterance in lwordFolder:\n",
    "        \n",
    "        utterFolder= '%s\\\\%s' % (wordFolder,utterance)\n",
    "        lutterFolder = os.listdir(utterFolder)\n",
    "        colourFolder ='%s\\\\%s' % (utterFolder,lutterFolder[0])\n",
    "        lcolourFolder = os.listdir(colourFolder)\n",
    "        frame = lcolourFolder[timestep]\n",
    "        i += 1\n",
    "        image= \"%s\\\\%s\" % (colourFolder,frame) \n",
    "        im=Image.open(image)\n",
    "        im = im.resize((224,224))\n",
    "        feature_vector = features(trial_model,im, transform=True).reshape((1,1, 1, 2622))\n",
    "        if i==1 :\n",
    "            feature_sequence=feature_vector #done because of need of same dim. for concatenation\n",
    "        else:\n",
    "            feature_sequence = np.concatenate((feature_sequence,feature_vector),axis=0)\n",
    "            \n",
    "    feature_sequence1 = feature_sequence[:,0,0,:]\n",
    "    return feature_sequence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_convertor(array):\n",
    "    convertor={}\n",
    "    for i in range(len(array)):\n",
    "        convertor[i]=array[i]\n",
    "    return convertor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference(dict, length):\n",
    "    ref = [None]*len(dict[1])\n",
    "\n",
    "    for i in range(0, len(dict[1])):\n",
    "        ref[i] = 0\n",
    "    for i in range(len(dict[1])):\n",
    "        for j in range(1, length):\n",
    "            ref[i] = ref[i] + dict[j][i]\n",
    "        ref[i] = ref[i]/length\n",
    "\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append(ref_dict, arr):\n",
    "    ref_dict.update({(len(ref_dict)+1): arr})\n",
    "    return ref_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_list_for_training=[0,1,2,3,4,5,6,10,11,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def people_extractor(inpDir,person_list):\n",
    "    People_dictionary={}\n",
    "    for people in range(0,len(person_list)):\n",
    "        feature_sequence=feature_extractor(inpDir,person_list[people],0,3)\n",
    "        convertor=dict_convertor(feature_sequence)\n",
    "        average=[]\n",
    "        average=reference(convertor,len(convertor))\n",
    "        average=np.array((average))\n",
    "        feat_array=average.reshape(1,2622)\n",
    "        People_dictionary=append(People_dictionary,feat_array)\n",
    "    return People_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.03537488e-05 2.69179969e-05 9.28771387e-05 ... 2.78823231e-06\n",
      "  3.78060906e-04 7.20144567e-04]]\n",
      "0\n",
      "[[6.40833334e-03 2.01818076e-03 1.78118343e-04 ... 2.68819867e-05\n",
      "  4.46896930e-04 3.64193419e-04]]\n",
      "1\n",
      "[[4.12250037e-04 3.81355553e-04 4.94044976e-05 ... 4.84345772e-05\n",
      "  6.46252511e-04 1.19746818e-04]]\n",
      "2\n",
      "[[1.50350405e-04 1.88538158e-05 5.56068490e-05 ... 1.12473192e-05\n",
      "  5.29548946e-04 2.15044238e-04]]\n",
      "3\n",
      "[[1.48100094e-04 4.68411972e-05 3.28964730e-05 ... 5.85897794e-06\n",
      "  5.41940581e-05 1.73809101e-04]]\n",
      "4\n",
      "[[5.96197996e-04 3.87119139e-04 9.21455463e-06 ... 3.80263485e-06\n",
      "  1.41481093e-04 2.78760788e-04]]\n",
      "5\n",
      "[[2.47419154e-04 6.48256135e-05 1.71964975e-05 ... 7.02096831e-06\n",
      "  8.09318869e-04 9.48089350e-04]]\n",
      "6\n",
      "[[2.19689102e-04 3.94609806e-05 6.39009578e-04 ... 3.57697432e-05\n",
      "  2.37491962e-04 1.02846096e-04]]\n",
      "7\n",
      "[[5.82142175e-05 3.82201528e-05 6.67964287e-05 ... 1.32054201e-05\n",
      "  1.01038714e-04 3.44952939e-04]]\n",
      "8\n",
      "[[2.03583384e-03 7.88221383e-05 2.92029144e-04 ... 3.75044157e-05\n",
      "  1.05454317e-04 1.41284065e-04]]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "people_dictionary=people_extractor('C:\\\\Users\\\\Om\\\\Desktop\\\\dataset',people_list_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('training_dict.pkl', 'wb')\n",
    "pickle.dump(people_dictionary, output)\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
